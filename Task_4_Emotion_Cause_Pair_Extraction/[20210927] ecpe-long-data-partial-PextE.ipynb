{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[20210927] ecpe-long-data-partial-PextE.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-hWXMW85WBd","executionInfo":{"status":"ok","timestamp":1632747373694,"user_tz":-480,"elapsed":31628,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}},"outputId":"877244ed-63d8-4045-bf86-96fbb77dbd41"},"source":["# connect to google colab\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"VjK4jQoO5oEj","executionInfo":{"status":"ok","timestamp":1632747572459,"user_tz":-480,"elapsed":316,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}}},"source":["# base path\n","DATA_PATH = './drive/MyDrive/fyp-code/codes/data/ecpe/'\n","MODEL_PATH = './drive/MyDrive/fyp-code/codes/model/ecpe/EC/long_partial/'"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zapJ8n435pgo","executionInfo":{"status":"ok","timestamp":1632747574083,"user_tz":-480,"elapsed":16,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}},"outputId":"eb0086a3-96c3-4a92-ed7b-0b2e5211c184"},"source":["############################################ IMPORT ##########################################################\n","import sys, os\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.nn import functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcYcFgdB5tCr","executionInfo":{"status":"ok","timestamp":1632747443821,"user_tz":-480,"elapsed":1568,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}},"outputId":"73e3e91e-74a0-4871-e9f8-c800ecdc4046"},"source":["# call the zip folder with all the self defined modules\n","base_folder = '/content/drive/MyDrive/fyp-code/codes'\n","\n","training_path = os.path.join(base_folder, \"utils_ecpe.zip\") \n","!unzip $training_path\n","\n","from funcs import *\n","from prepare_data import *"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/fyp-code/codes/utils_ecpe.zip\n","  inflating: funcs.py                \n","  inflating: prepare_data.py         \n"]}]},{"cell_type":"code","metadata":{"id":"YJJu5ALn5vwy","executionInfo":{"status":"ok","timestamp":1632747576191,"user_tz":-480,"elapsed":518,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}}},"source":["############################################ FLAGS ############################################################\n","# file names of the data files\n","LOOKUP = 'ecpe_long_partial_annotated.csv'\n","DATA = 'long_partial'\n","TRAIN_DATA = 'ecpe_long_partial_train'\n","VAL_DATA = 'ecpe_long_partial_val'\n","\n","# fixed parameters\n","train_file_path = DATA_PATH + LOOKUP                                # clause keyword file\n","w2v_file = DATA_PATH+'w2v_200.txt'                                  # embedding file\n","embedding_dim = 200                                                 # dimension of word embedding\n","embedding_dim_pos = 30                                              # dimension of position embedding\n","max_sen_len = 30                                                    # max number of tokens per sentence\n","max_doc_len = 41                                                    # max number of tokens per document\n","n_class = 2                                                         # number of distinct class\n","training_epochs = 10                                                # number of train epochs\n","keep_prob1 = 0.8                                                    # word embedding training dropout keep prob\n","keep_prob2 = 1.0                                                    # softmax layer dropout keep prob\n","keep_prob3 = 1.0                                                    # softmax layer dropout keep prob\n","l2_reg = 0.00010                                                    # l2 regularization\n","cause = 1.0                                                         # lambda1\n","pos = 1.0                                                           # lambda2\n","pair = 2.5                                                          # lambda3\n","\n","# hyperparameters considered for tuning (will be tuned later when the class is called)\n","n_hidden = None                                                     # number of hidden unit\n","batch_size = None                                                   # number of example per batch\n","learning_rate = None                                                # learning rate\n","diminish_factor = None                                              # give less weight to -ve examples"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"frumvms955MM","executionInfo":{"status":"ok","timestamp":1632747579196,"user_tz":-480,"elapsed":296,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}}},"source":["############################################ MODEL ############################################################\n","class E2E_PextE(nn.Module):\n","    def __init__(self, embedding_dim, embedding_dim_pos, sen_len, doc_len, keep_prob1, keep_prob2, \\\n","                 keep_prob3, n_hidden, n_class):\n","        super(E2E_PextE, self).__init__()\n","        self.embedding_dim = embedding_dim; self.embedding_dim_pos = embedding_dim_pos \n","        self.sen_len = sen_len; self.doc_len = doc_len\n","        self.keep_prob1 = keep_prob1; self.keep_prob2 = keep_prob2\n","        self.n_hidden = n_hidden; self.n_class = n_class\n","\n","        self.dropout1 = nn.Dropout(p = 1 - keep_prob1)\n","        self.dropout2 = nn.Dropout(p = 1 - keep_prob2)\n","        self.dropout3 = nn.Dropout(p = 1 - keep_prob3)\n","        self.relu = nn.ReLU()\n","        self.pos_linear = nn.Linear(2*n_hidden, n_class)\n","        self.cause_linear = nn.Linear(2*n_hidden, n_class)\n","        self.pair_linear1 = nn.Linear(4*n_hidden + embedding_dim_pos, n_hidden//2)\n","        self.pair_linear2 = nn.Linear(n_hidden//2, n_class)\n","        self.word_bilstm = nn.LSTM(embedding_dim, n_hidden, batch_first = True, bidirectional = True)\n","        self.cause_bilstm = nn.LSTM(2*n_hidden + n_class, n_hidden, batch_first = True, bidirectional = True)\n","        self.pos_bilstm = nn.LSTM(2*n_hidden, n_hidden, batch_first = True, bidirectional = True)\n","        self.attention = Attention(n_hidden, sen_len)\n","\n","    def get_clause_embedding(self, x):\n","        '''\n","        input shape: [batch_size, doc_len, sen_len, embedding_dim]\n","        output shape: [batch_size, doc_len, 2 * n_hidden]\n","        '''\n","        x = x.reshape(-1, self.sen_len, self.embedding_dim)\n","        x = self.dropout1(x)\n","        # x is of shape (batch_size * max_doc_len, max_sen_len, embedding_dim)\n","        x, hidden_states = self.word_bilstm(x.float())\n","        # x is of shape (batch_size * max_doc_len, max_sen_len, 2 * n_hidden)\n","        s = self.attention(x).reshape(-1, self.doc_len, 2 * self.n_hidden)\n","        # s is of shape (batch_size, max_doc_len, 2 * n_hidden)\n","        return s\n","\n","    def get_emotion_prediction(self, x):\n","        '''\n","        input shape: [batch_size, doc_len, 2 * n_hidden]\n","        output(s) shape: [batch_size, doc_len, 2 * n_hidden], [batch_size, doc_len, n_class]\n","        '''\n","        x_context, hidden_states = self.pos_bilstm(x.float())\n","        # x_context is of shape (batch_size, max_doc_len, 2 * n_hidden)\n","        x = x_context.reshape(-1, 2 * self.n_hidden)\n","        x = self.dropout2(x)\n","        # x is of shape (batch_size * max_doc_len, 2 * n_hidden)\n","        pred_pos = F.softmax(self.pos_linear(x), dim = -1)\n","        # pred_pos is of shape (batch_size * max_doc_len, n_class)\n","        pred_pos = pred_pos.reshape(-1, self.doc_len, self.n_class)\n","        # pred_pos is of shape (batch_size * max_doc_len, n_class)\n","        return x_context, pred_pos\n","\n","    def get_cause_prediction(self, x):\n","        '''\n","        input shape: [batch_size, doc_len, 2 * n_hidden + n_class]\n","        output(s) shape: [batch_size, doc_len, 2 * n_hidden], [batch_size, doc_len, n_class]\n","        '''\n","        x_context, hidden_states = self.cause_bilstm(x.float())\n","        # x_context is of shape (batch_size, max_doc_len, 2 * n_hidden)\n","        x = x_context.reshape(-1, 2 * self.n_hidden)\n","        x = self.dropout2(x)\n","        # x is of shape (batch_size * max_doc_len, 2 * n_hidden)\n","        pred_cause = F.softmax(self.cause_linear(x), dim = -1)\n","        # pred_pos is of shape (batch_size * max_doc_len, n_class)\n","        pred_cause = pred_cause.reshape(-1, self.doc_len, self.n_class)\n","        # pred_pos is of shape (batch_size * max_doc_len, n_class)\n","        return x_context, pred_cause\n","\n","    def get_pair_prediction(self, x1, x2, distance):\n","        '''\n","        input(s) shape: [batch_size * doc_len, 2 * n_hidden], [batch_size * doc_len, 2 * n_hidden], \n","                        [batch_size, doc_len * doc_len, embedding_dim_pos] \n","        output shape: [batch_size, doc_len * doc_len, n_class]\n","        '''        \n","        x = create_pairs(x1, x2)\n","        # x is of shape (batch_size, max_doc_len * max_doc_len, 4 * n_hidden)\n","        x_distance = torch.cat([x, distance.float()], -1)\n","        # x_distance is of shape (batch_size, max_doc_len * max_doc_len, 4 * n_hidden + embedding_dim_pos)\n","        x_distance = x_distance.reshape(-1, 4 * self.n_hidden + self.embedding_dim_pos)\n","        x_distance = self.dropout3(x_distance)\n","        # x is of shape (batch_size * max_doc_len * max_doc_len, 4 * n_hidden + embedding_dim_pos)\n","        pred_pair = F.softmax(self.pair_linear2(self.relu(self.pair_linear1(x_distance))), dim = -1)\n","        # pred_pair is of shape (batch_size * max_doc_len * max_doc_len, n_class)\n","        pred_pair = pred_pair.reshape(-1, self.doc_len * self.doc_len, self.n_class)\n","        # pred_pair is of shape (batch_size, max_doc_len * max_doc_len, n_class)\n","        return pred_pair\n","\n","    def forward(self, x, distance):\n","        '''\n","        input(s) shape: [batch_size, doc_len, sen_len, embedding_dim], \n","                        [batch_size, doc_len * doc_len, embedding_dim_pos]\n","        output(s) shape: [batch_size, doc_len, n_class], [batch_size, doc_len, n_class], \n","                         [batch_size, doc_len * doc_len, n_class]\n","        '''\n","        s = self.get_clause_embedding(x)\n","        x_pos, pred_pos = self.get_emotion_prediction(s)\n","        s_pred_pos = torch.cat([s, pred_pos], 2)\n","        x_cause, pred_cause = self.get_cause_prediction(s_pred_pos)\n","        pred_pair = self.get_pair_prediction(x_pos, x_cause, distance)\n","        return pred_pos, pred_cause, pred_pair"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"pV2wuoeL55OU","executionInfo":{"status":"ok","timestamp":1632747579948,"user_tz":-480,"elapsed":469,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}}},"source":["def load_data_pair(input_file, word_idx, max_doc_len = 75, max_sen_len = 45):\n","    print('load data_file: {}'.format(input_file))\n","    pair_id_all, y_position, y_cause, y_pair, x, sen_len, doc_len, distance = [], [], [], [], [], [], [], []\n","    n_cut = 0\n","    inputFile = open(input_file, 'r')\n","    while True:\n","        line = inputFile.readline()\n","        if line == '': break\n","        line = line.strip().split()\n","        doc_id = int(line[0])\n","        d_len = int(line[1])\n","        ######################################## doc_len_condition ########################################\n","        if d_len >= max_doc_len :\n","            for i in range(d_len+1) :\n","                line = inputFile.readline().strip().split(',')\n","            continue\n","        ######################################## doc_len_condition ########################################\n","\n","        pairs = eval('[' + inputFile.readline().strip() + ']')\n","        pos_list, cause_list = zip(*pairs)\n","        pairs = [[pos_list[i], cause_list[i]] for i in range(len(pos_list))]\n","        pair_id_all.extend([doc_id*10000+p[0]*100+p[1] for p in pairs])\n","        y_position_tmp, y_cause_tmp, y_pair_tmp, sen_len_tmp, x_tmp, distance_tmp = \\\n","        np.zeros((max_doc_len, 2)), np.zeros((max_doc_len, 2)), np.zeros((max_doc_len * max_doc_len, 2)), \\\n","        np.zeros((max_doc_len, )), np.zeros((max_doc_len, max_sen_len)), np.zeros((max_doc_len * max_doc_len, ))\n","\n","        for i in range(d_len):\n","            line = inputFile.readline().strip().split(',')\n","            words = line[-1]\n","            sen_len_tmp[i] = min(len(words.split()), max_sen_len)\n","            for j, word in enumerate(words.split()):\n","                word = word.lower()\n","                if j >= max_sen_len:\n","                    n_cut += 1\n","                    break\n","                elif word not in word_idx : x_tmp[i][j] = 24166\n","                else : x_tmp[i][j] = int(word_idx[word])\n","\n","        for i in range(d_len):\n","            for j in range(d_len):\n","                # Check whether i is an emotion clause\n","                if i+1 in pos_list :\n","                    y_position_tmp[i][0] = 0; y_position_tmp[i][1] = 1\n","                else :\n","                    y_position_tmp[i][0] = 1; y_position_tmp[i][1] = 0\n","                # Check whether j is a cause clause\n","                if j+1 in cause_list :\n","                    y_cause_tmp[j][0] = 0; y_cause_tmp[j][1] = 1\n","                else :\n","                    y_cause_tmp[j][0] = 1; y_cause_tmp[j][1] = 0\n","                # Check whether i, j clauses are emotion cause pairs\n","                pair_id_curr = doc_id*10000+(i+1)*100+(j+1)\n","                if pair_id_curr in pair_id_all :\n","                    y_pair_tmp[i*max_doc_len+j][0] = 0; y_pair_tmp[i*max_doc_len+j][1] = 1\n","                else :\n","                    y_pair_tmp[i*max_doc_len+j][0] = 1; y_pair_tmp[i*max_doc_len+j][1] = 0\n","                # Find the distance between the clauses, and use the same embedding beyond 10 clauses\n","                distance_tmp[i*max_doc_len+j] = min(max(j-i+100, 90), 110)\n","\n","        y_position.append(y_position_tmp)\n","        y_cause.append(y_cause_tmp)\n","        y_pair.append(y_pair_tmp)\n","        x.append(x_tmp)\n","        sen_len.append(sen_len_tmp)\n","        doc_len.append(d_len)\n","        distance.append(distance_tmp)\n","\n","    y_position, y_cause, y_pair, x, sen_len, doc_len, distance = map(torch.tensor, \\\n","    [y_position, y_cause, y_pair, x, sen_len, doc_len, distance])\n","\n","    for var in ['y_position', 'y_cause', 'y_pair', 'x', 'sen_len', 'doc_len', 'distance']:\n","        print('{}.shape {}'.format( var, eval(var).shape ))\n","    print('n_cut {}'.format(n_cut))\n","    print('load data done!\\n')\n","    return y_position, y_cause, y_pair, x, sen_len, doc_len, distance"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mvI10_W655Ql","executionInfo":{"status":"ok","timestamp":1632747580785,"user_tz":-480,"elapsed":547,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}}},"source":["############################################ TRAIN #####################################################\n","def train_and_eval(Model, pos_cause_criterion, pair_criterion, optimizer, n_hidden, batch_size, learning_rate, diminish_factor):\n","    word_idx_rev, word_id_mapping, word_embedding, pos_embedding = load_w2v(\n","        embedding_dim, embedding_dim_pos, train_file_path, w2v_file)\n","    word_embedding = torch.from_numpy(word_embedding)\n","    # Train distance embeddings\n","    pos_embedding = torch.autograd.Variable(torch.from_numpy(pos_embedding))\n","    pos_embedding.requires_grad_(True)\n","    #torch.save(word_embedding, MODEL_PATH+DATA+'_'+'word_embedding'+'.pth')\n","    torch.save(word_embedding, f'{MODEL_PATH}{DATA}_word_embedding_nhid-{n_hidden}_bs-{batch_size}_lr-{learning_rate}_dimf-{diminish_factor}.pth')\n","    #torch.save(word_id_mapping, MODEL_PATH+DATA+'_'+'word_id_mapping'+'.pth')\n","    torch.save(word_id_mapping, f'{MODEL_PATH}{DATA}_word_id_mapping_nhid-{n_hidden}_bs-{batch_size}_lr-{learning_rate}_dimf-{diminish_factor}.pth')\n","    acc_cause_list, p_cause_list, r_cause_list, f1_cause_list = [], [], [], []\n","    acc_pos_list, p_pos_list, r_pos_list, f1_pos_list = [], [], [], []\n","    acc_pair_list, p_pair_list, r_pair_list, f1_pair_list = [], [], [], []\n","    #################################### LOOP OVER FOLDS ####################################\n","    # do 5 fold cross validation\n","    for fold in range(1, 2):\n","        print('############# fold {} begin ###############'.format(fold))\n","        ############################# RE-INITIALIZE MODEL PARAMETERS #############################\n","        for layer in Model.parameters():\n","            nn.init.uniform_(layer.data, -0.10, 0.10)\n","        #################################### TRAIN/TEST DATA ####################################\n","        train_file_name = '{}_{}.txt'.format(TRAIN_DATA,fold)\n","        val_file_name = '{}_{}.txt'.format(VAL_DATA,fold)\n","        tr_y_position, tr_y_cause, tr_y_pair, tr_x, tr_sen_len, tr_doc_len, tr_distance = load_data_pair(\n","                        DATA_PATH+train_file_name, word_id_mapping, max_doc_len, max_sen_len)\n","        val_y_position, val_y_cause, val_y_pair, val_x, val_sen_len, val_doc_len, val_distance = \\\n","            load_data_pair(DATA_PATH+val_file_name, word_id_mapping, max_doc_len, max_sen_len)\n","        max_f1_cause, max_f1_pos, max_f1_pair, max_f1_avg = [-1.] * 4\n","        #################################### LOOP OVER EPOCHS ####################################\n","        for epoch in range(1, training_epochs + 1):\n","            step = 1\n","            #################################### GET BATCH DATA ####################################\n","            for train, _ in get_batch_data_pair(\n","                tr_x, tr_sen_len, tr_doc_len, tr_y_position, tr_y_cause, tr_y_pair, tr_distance, batch_size):\n","                tr_x_batch, tr_sen_len_batch, tr_doc_len_batch, tr_true_y_pos, tr_true_y_cause, \\\n","                tr_true_y_pair, tr_distance_batch = train\n","                Model.train()\n","                tr_pred_y_pos, tr_pred_y_cause, tr_pred_y_pair = Model(embedding_lookup(word_embedding, \\\n","                tr_x_batch), embedding_lookup(pos_embedding, tr_distance_batch))\n","                ############################## LOSS FUNCTION AND OPTIMIZATION ##############################\n","                loss = pos_cause_criterion(tr_true_y_pos, tr_pred_y_pos, tr_doc_len_batch)*pos + \\\n","                pos_cause_criterion(tr_true_y_cause, tr_pred_y_cause, tr_doc_len_batch)*cause + \\\n","                pair_criterion(tr_true_y_pair, tr_pred_y_pair, tr_doc_len_batch)*pair\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","                #################################### PRINT AFTER EPOCHS ####################################\n","                if step % 25 == 0:\n","                    # print(Model.pair_linear.weight.shape); print(Model.pair_linear.weight.grad)\n","                    print('Fold {}, Epoch {}, step {}: train loss {:.4f} '.format(fold, epoch, step, loss))\n","                    acc, p, r, f1 = acc_prf_aux(tr_pred_y_pos, tr_true_y_pos, tr_doc_len_batch)\n","                    print('emotion_predict: train acc {:.4f} p {:.4f} r {:.4f} f1 score {:.4f}'.format(\n","                            acc, p, r, f1))\n","                    acc, p, r, f1 = acc_prf_aux(tr_pred_y_cause, tr_true_y_cause, tr_doc_len_batch)\n","                    print('cause_predict: train acc {:.4f} p {:.4f} r {:.4f} f1 score {:.4f}'.format(\n","                            acc, p, r, f1))\n","                    acc, p, r, f1 = acc_prf_pair(tr_pred_y_pair, tr_true_y_pair, tr_doc_len_batch)\n","                    print('pair_predict: train acc {:.4f} p {:.4f} r {:.4f} f1 score {:.4f}'.format(\n","                            acc, p, r, f1)) \n","                step += 1\n","            #################################### TEST ON 1 FOLD ####################################\n","            with torch.no_grad():\n","                Model.eval()\n","                val_pred_y_pos, val_pred_y_cause, val_pred_y_pair = Model(embedding_lookup(word_embedding, \\\n","                val_x), embedding_lookup(pos_embedding, val_distance))\n","\n","                loss = pos_cause_criterion(val_y_position, val_pred_y_pos, val_doc_len)*pos + \\\n","                pos_cause_criterion(val_y_cause, val_pred_y_cause, val_doc_len)*cause + \\\n","                pair_criterion(val_y_pair, val_pred_y_pair, val_doc_len)*pair\n","                print('Fold {} Epoch {} val loss {:.4f}'.format(fold, epoch, loss))\n","                acc, p, r, f1 = acc_prf_aux(val_pred_y_pos, val_y_position, val_doc_len)\n","                result_avg_pos = [acc, p, r, f1]\n","                if f1 > max_f1_pos:\n","                    max_acc_pos, max_p_pos, max_r_pos, max_f1_pos = acc, p, r, f1\n","                print('emotion_predict: val acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc, p, r, f1))\n","                print('max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}\\n'.format(\n","                    max_acc_pos, max_p_pos, max_r_pos, max_f1_pos))\n","\n","                acc, p, r, f1 = acc_prf_aux(val_pred_y_cause, val_y_cause, val_doc_len)\n","                result_avg_cause = [acc, p, r, f1]\n","                if f1 > max_f1_cause:\n","                    max_acc_cause, max_p_cause, max_r_cause, max_f1_cause = acc, p, r, f1\n","                print('cause_predict: val acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc, p, r, f1))\n","                print('max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}\\n'.format(\n","                    max_acc_cause, max_p_cause, max_r_cause, max_f1_cause))\n","\n","                acc, p, r, f1 = acc_prf_pair(val_pred_y_pair, val_y_pair, val_doc_len)\n","                result_avg_pair = [acc, p, r, f1]\n","                if f1 > max_f1_pair:\n","                    max_acc_pair, max_p_pair, max_r_pair, max_f1_pair = acc, p, r, f1\n","                print('pair_predict: val acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc, p, r, f1))\n","                print('max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}\\n'.format(\n","                    max_acc_pair, max_p_pair, max_r_pair, max_f1_pair))\n","\n","            #################################### STORE BETTER PAIR F1 ####################################\n","            if result_avg_pair[-1] > max_f1_avg:\n","                #torch.save(pos_embedding, MODEL_PATH+DATA+\"_\"+\"pos_embedding_fold_{}.pth\".format(fold))\n","                torch.save(pos_embedding, f'{MODEL_PATH}{DATA}_pos_embedding_fold-{fold}_nhid-{n_hidden}_bs-{batch_size}_lr-{learning_rate}_dimf-{diminish_factor}.pth')\n","                #torch.save(Model.state_dict(), MODEL_PATH+DATA+\"_\"+\"E2E-EC_fold_{}.pth\".format(fold))\n","                torch.save(Model.state_dict(), f'{MODEL_PATH}{DATA}_E2E-EC_fold-{fold}_nhid-{n_hidden}_bs-{batch_size}_lr-{learning_rate}_dimf-{diminish_factor}.pth')\n","                \n","                max_f1_avg = result_avg_pair[-1]\n","                result_avg_cause_max = result_avg_cause\n","                result_avg_pos_max = result_avg_pos\n","                result_avg_pair_max = result_avg_pair\n","\n","            print('avg max cause: max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}'.format(\n","                result_avg_cause_max[0], result_avg_cause_max[1], result_avg_cause_max[2], result_avg_cause_max[3]))\n","            print('avg max pos: max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}'.format(\n","                result_avg_pos_max[0], result_avg_pos_max[1], result_avg_pos_max[2], result_avg_pos_max[3]))\n","            print('avg max pair: max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}\\n'.format(\n","                result_avg_pair_max[0], result_avg_pair_max[1], result_avg_pair_max[2], result_avg_pair_max[3]))\n","\n","        print('############# fold {} end ###############'.format(fold))\n","        acc_cause_list.append(result_avg_cause_max[0])\n","        p_cause_list.append(result_avg_cause_max[1])\n","        r_cause_list.append(result_avg_cause_max[2])\n","        f1_cause_list.append(result_avg_cause_max[3])\n","        acc_pos_list.append(result_avg_pos_max[0])\n","        p_pos_list.append(result_avg_pos_max[1])\n","        r_pos_list.append(result_avg_pos_max[2])\n","        f1_pos_list.append(result_avg_pos_max[3])\n","        acc_pair_list.append(result_avg_pair_max[0])\n","        p_pair_list.append(result_avg_pair_max[1])\n","        r_pair_list.append(result_avg_pair_max[2])\n","        f1_pair_list.append(result_avg_pair_max[3])\n","\n","    #################################### FINAL TEST RESULTS ON 10 FOLDS ####################################\n","    all_results = [acc_cause_list, p_cause_list, r_cause_list, f1_cause_list, \\\n","    acc_pos_list, p_pos_list, r_pos_list, f1_pos_list, acc_pair_list, p_pair_list, r_pair_list, f1_pair_list,]\n","    acc_cause, p_cause, r_cause, f1_cause, acc_pos, p_pos, r_pos, f1_pos, acc_pair, p_pair, r_pair, f1_pair = \\\n","        map(lambda x: np.array(x).mean(), all_results)\n","    print('\\ncause_predict: val f1 in 1 fold: {}'.format(np.array(f1_cause_list).reshape(-1,1)))\n","    print('average : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}\\n'.format(acc_cause, p_cause, r_cause, f1_cause))\n","    print('emotion_predict: val f1 in 1 fold: {}'.format(np.array(f1_pos_list).reshape(-1,1)))\n","    print('average : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}\\n'.format(acc_pos, p_pos, r_pos, f1_pos))\n","    print('pair_predict: val f1 in 1 fold: {}'.format(np.array(f1_pair_list).reshape(-1,1)))\n","    print('average : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}\\n'.format(acc_pair, p_pair, r_pair, f1_pair))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TzNgcZUD55U9","executionInfo":{"status":"ok","timestamp":1632747581952,"user_tz":-480,"elapsed":4,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}}},"source":[""],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iYXn6JV56M1U"},"source":["## Calling the class for the varying hyperparamters"]},{"cell_type":"code","metadata":{"id":"Ab_FwHbh55XC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632747889514,"user_tz":-480,"elapsed":15824,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}},"outputId":"87a3a939-b4a2-44fa-d371-cf6b7d97085a"},"source":["# HYPERPARAMETERS TO BE TUNED\n","N_HIDDEN = 128\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.005\n","DIMINISH_FACTOR = 0.400\n","\n","# MAIN MODEL\n","Model = E2E_PextE(embedding_dim, embedding_dim_pos, max_sen_len, max_doc_len, \\\n","keep_prob1, keep_prob2, keep_prob3, N_HIDDEN, n_class)\n","Model.to(device)\n","print(Model)\n","x = torch.rand([BATCH_SIZE, max_doc_len, max_sen_len, embedding_dim]).to(device)\n","distance = torch.rand([BATCH_SIZE, max_doc_len * max_doc_len, embedding_dim_pos]).to(device)\n","pred_pos, pred_cause, pred_pair = Model(x, distance)\n","print(\"Random i/o shapes x: {}, distance: {}, y_pos: {}, y_cause: {}, y_pair: {}\".format(\n","    x.shape, distance.shape, pred_pos.shape, pred_cause.shape, pred_pair.shape))\n","pos_cause_criterion = ce_loss_aux(); pair_criterion = ce_loss_pair(DIMINISH_FACTOR)\n","optimizer = optim.Adam(Model.parameters(), lr=LEARNING_RATE, weight_decay=l2_reg)\n","train_and_eval(Model, pos_cause_criterion, pair_criterion, optimizer, N_HIDDEN, BATCH_SIZE, LEARNING_RATE, DIMINISH_FACTOR)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["E2E_PextE(\n","  (dropout1): Dropout(p=0.19999999999999996, inplace=False)\n","  (dropout2): Dropout(p=0.0, inplace=False)\n","  (dropout3): Dropout(p=0.0, inplace=False)\n","  (relu): ReLU()\n","  (pos_linear): Linear(in_features=256, out_features=2, bias=True)\n","  (cause_linear): Linear(in_features=256, out_features=2, bias=True)\n","  (pair_linear1): Linear(in_features=542, out_features=64, bias=True)\n","  (pair_linear2): Linear(in_features=64, out_features=2, bias=True)\n","  (word_bilstm): LSTM(200, 128, batch_first=True, bidirectional=True)\n","  (cause_bilstm): LSTM(258, 128, batch_first=True, bidirectional=True)\n","  (pos_bilstm): LSTM(256, 128, batch_first=True, bidirectional=True)\n","  (attention): Attention(\n","    (linear1): Linear(in_features=256, out_features=256, bias=True)\n","    (linear2): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")\n","Random i/o shapes x: torch.Size([64, 41, 30, 200]), distance: torch.Size([64, 1681, 30]), y_pos: torch.Size([64, 41, 2]), y_cause: torch.Size([64, 41, 2]), y_pair: torch.Size([64, 1681, 2])\n","\n","load embedding...\n","w2v_file: ./drive/MyDrive/fyp-code/codes/data/ecpe/w2v_200.txt\n","all_words: 2789 hit_words: 2038\n","embedding.shape: (2791, 200) embedding_pos.shape: (201, 30)\n","load embedding done!\n","\n","############# fold 1 begin ###############\n","load data_file: ./drive/MyDrive/fyp-code/codes/data/ecpe/ecpe_long_partial_train_1.txt\n","y_position.shape torch.Size([63, 41, 2])\n","y_cause.shape torch.Size([63, 41, 2])\n","y_pair.shape torch.Size([63, 1681, 2])\n","x.shape torch.Size([63, 41, 30])\n","sen_len.shape torch.Size([63, 41])\n","doc_len.shape torch.Size([63])\n","distance.shape torch.Size([63, 1681])\n","n_cut 22\n","load data done!\n","\n","load data_file: ./drive/MyDrive/fyp-code/codes/data/ecpe/ecpe_long_partial_val_1.txt\n","y_position.shape torch.Size([19, 41, 2])\n","y_cause.shape torch.Size([19, 41, 2])\n","y_pair.shape torch.Size([19, 1681, 2])\n","x.shape torch.Size([19, 41, 30])\n","sen_len.shape torch.Size([19, 41])\n","doc_len.shape torch.Size([19])\n","distance.shape torch.Size([19, 1681])\n","n_cut 8\n","load data done!\n","\n","Fold 1 Epoch 1 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 2 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 3 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 4 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 5 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 6 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 7 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 8 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 9 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","Fold 1 Epoch 10 val loss 14.9595\n","emotion_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","cause_predict: val acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","pair_predict: val acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","avg max cause: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pos: max_acc 0.9369 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","avg max pair: max_acc 0.9970 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n","\n","############# fold 1 end ###############\n","\n","cause_predict: val f1 in 1 fold: [[0.]]\n","average : acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","\n","emotion_predict: val f1 in 1 fold: [[0.]]\n","average : acc 0.9369 p 0.0000 r 0.0000 f1 0.0000\n","\n","pair_predict: val f1 in 1 fold: [[0.]]\n","average : acc 0.9970 p 0.0000 r 0.0000 f1 0.0000\n","\n"]}]},{"cell_type":"code","metadata":{"id":"vwLit-0S55Z4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6e0h0Cv8jEt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632747909694,"user_tz":-480,"elapsed":15709,"user":{"displayName":"Nicholas Neo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17863111022281221474"}},"outputId":"865a8de2-b23d-4c9c-cc1b-ce847a2e5f34"},"source":["# HYPERPARAMETERS TO BE TUNED\n","N_HIDDEN = 128\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","DIMINISH_FACTOR = 0.100\n","\n","# MAIN MODEL\n","Model = E2E_PextE(embedding_dim, embedding_dim_pos, max_sen_len, max_doc_len, \\\n","keep_prob1, keep_prob2, keep_prob3, N_HIDDEN, n_class)\n","Model.to(device)\n","print(Model)\n","x = torch.rand([BATCH_SIZE, max_doc_len, max_sen_len, embedding_dim]).to(device)\n","distance = torch.rand([BATCH_SIZE, max_doc_len * max_doc_len, embedding_dim_pos]).to(device)\n","pred_pos, pred_cause, pred_pair = Model(x, distance)\n","print(\"Random i/o shapes x: {}, distance: {}, y_pos: {}, y_cause: {}, y_pair: {}\".format(\n","    x.shape, distance.shape, pred_pos.shape, pred_cause.shape, pred_pair.shape))\n","pos_cause_criterion = ce_loss_aux(); pair_criterion = ce_loss_pair(DIMINISH_FACTOR)\n","optimizer = optim.Adam(Model.parameters(), lr=LEARNING_RATE, weight_decay=l2_reg)\n","train_and_eval(Model, pos_cause_criterion, pair_criterion, optimizer, N_HIDDEN, BATCH_SIZE, LEARNING_RATE, DIMINISH_FACTOR)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["E2E_PextE(\n","  (dropout1): Dropout(p=0.19999999999999996, inplace=False)\n","  (dropout2): Dropout(p=0.0, inplace=False)\n","  (dropout3): Dropout(p=0.0, inplace=False)\n","  (relu): ReLU()\n","  (pos_linear): Linear(in_features=256, out_features=2, bias=True)\n","  (cause_linear): Linear(in_features=256, out_features=2, bias=True)\n","  (pair_linear1): Linear(in_features=542, out_features=64, bias=True)\n","  (pair_linear2): Linear(in_features=64, out_features=2, bias=True)\n","  (word_bilstm): LSTM(200, 128, batch_first=True, bidirectional=True)\n","  (cause_bilstm): LSTM(258, 128, batch_first=True, bidirectional=True)\n","  (pos_bilstm): LSTM(256, 128, batch_first=True, bidirectional=True)\n","  (attention): Attention(\n","    (linear1): Linear(in_features=256, out_features=256, bias=True)\n","    (linear2): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")\n","Random i/o shapes x: torch.Size([64, 41, 30, 200]), distance: torch.Size([64, 1681, 30]), y_pos: torch.Size([64, 41, 2]), y_cause: torch.Size([64, 41, 2]), y_pair: torch.Size([64, 1681, 2])\n","\n","load embedding...\n","w2v_file: ./drive/MyDrive/fyp-code/codes/data/ecpe/w2v_200.txt\n","all_words: 2789 hit_words: 2038\n","embedding.shape: (2791, 200) embedding_pos.shape: (201, 30)\n","load embedding done!\n","\n","############# fold 1 begin ###############\n","load data_file: ./drive/MyDrive/fyp-code/codes/data/ecpe/ecpe_long_partial_train_1.txt\n","y_position.shape torch.Size([63, 41, 2])\n","y_cause.shape torch.Size([63, 41, 2])\n","y_pair.shape torch.Size([63, 1681, 2])\n","x.shape torch.Size([63, 41, 30])\n","sen_len.shape torch.Size([63, 41])\n","doc_len.shape torch.Size([63])\n","distance.shape torch.Size([63, 1681])\n","n_cut 22\n","load data done!\n","\n","load data_file: ./drive/MyDrive/fyp-code/codes/data/ecpe/ecpe_long_partial_val_1.txt\n","y_position.shape torch.Size([19, 41, 2])\n","y_cause.shape torch.Size([19, 41, 2])\n","y_pair.shape torch.Size([19, 1681, 2])\n","x.shape torch.Size([19, 41, 30])\n","sen_len.shape torch.Size([19, 41])\n","doc_len.shape torch.Size([19])\n","distance.shape torch.Size([19, 1681])\n","n_cut 8\n","load data done!\n","\n","Fold 1 Epoch 1 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 2 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 3 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 4 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 5 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 6 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 7 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 8 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 9 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","Fold 1 Epoch 10 val loss 5.1870\n","emotion_predict: val acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","\n","cause_predict: val acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","\n","pair_predict: val acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","avg max cause: max_acc 0.9336 max_p 0.3333 max_r 0.0526 max_f1 0.0909\n","avg max pos: max_acc 0.0631 max_p 0.0631 max_r 1.0000 max_f1 0.1187\n","avg max pair: max_acc 0.0030 max_p 0.0030 max_r 1.0000 max_f1 0.0061\n","\n","############# fold 1 end ###############\n","\n","cause_predict: val f1 in 1 fold: [[0.09090909]]\n","average : acc 0.9336 p 0.3333 r 0.0526 f1 0.0909\n","\n","emotion_predict: val f1 in 1 fold: [[0.11875]]\n","average : acc 0.0631 p 0.0631 r 1.0000 f1 0.1187\n","\n","pair_predict: val f1 in 1 fold: [[0.00606641]]\n","average : acc 0.0030 p 0.0030 r 1.0000 f1 0.0061\n","\n"]}]},{"cell_type":"code","metadata":{"id":"OE-tWRS-8kuh"},"source":[""],"execution_count":null,"outputs":[]}]}