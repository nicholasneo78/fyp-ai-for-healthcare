{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c6da78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nicholasneo78\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import preprocessor as p # tweet-preprocessor\n",
    "import cleantext\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.stem.WordNetLemmatizer().lemmatize('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b5c55fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS_LIST = list(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f18fb506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eleven', 'yourself', 'whereupon', 'hereupon', 'amongst', 'cannot', 'an', 'he', 'whereas', 'be', 'yours', 'fifty', 'each', 'name', 'sometimes', 'nowhere', 'latter', 'until', 'itself', 'thru', 'whereby', 'six', 'any', 'us', 'and', 'would', 'part', 'now', 'every', 'noone', 'but', 'once', 'first', 'four', 'done', 'my', 'both', 'bottom', 'it', 'hereafter', 'against', 'myself', 'seems', 'next', 'then', 'thereafter', 'other', 'she', 'get', 'is', 'interest', 'they', 'below', 'serious', 'may', 'not', 'about', 'above', 'so', 'their', 'up', 'the', 'three', 'on', 'moreover', 'ltd', 'never', 'system', 'always', 'herself', 'describe', 're', 'nobody', 'everyone', 'again', 'whole', 'of', 'why', 'became', 'onto', 'fill', 'here', 'has', 'rather', 'upon', 'thereby', 'beside', 'else', 'which', 'made', 'another', 'whither', 'among', 'cry', 'ie', 'five', 'them', 'find', 'such', 'along', 'own', 'what', 'whether', 'yet', 'see', 'detail', 'others', 'same', 'had', 'herein', 'thin', 'as', 'themselves', 'therefore', 'behind', 'his', 'further', 'thence', 'full', 'if', 'too', 'no', 'thus', 'towards', 'beforehand', 'toward', 'please', 'few', 'were', 'side', 'himself', 'thick', 'well', 'into', 'move', 'only', 'will', 'our', 'whom', 'something', 'am', 'been', 'after', 'mill', 'could', 'un', 'amoungst', 'someone', 'formerly', 'last', 'eg', 'everything', 'fire', 'elsewhere', 'several', 'namely', 'although', 'except', 'otherwise', 'seeming', 'nevertheless', 'sincere', 'its', 'anything', 'him', 'should', 'back', 'hers', 'off', 'at', 'put', 'indeed', 'nor', 'go', 'very', 'afterwards', 'whatever', 'often', 'less', 'where', 'due', 'ourselves', 'being', 'though', 'mine', 'before', 'neither', 'hundred', 'whoever', 'everywhere', 'can', 'throughout', 'since', 'con', 'have', 'anyone', 'amount', 'across', 'from', 'call', 'becomes', 'front', 'however', 'under', 'also', 'for', 'meanwhile', 'perhaps', 'two', 'seem', 'within', 'your', 'whence', 'none', 'was', 'are', 'keep', 'during', 'you', 'already', 'inc', 'all', 'becoming', 'ten', 'do', 'cant', 'anyway', 'hereby', 'whose', 'third', 'anywhere', 'via', 'seemed', 'wherein', 'to', 'between', 'than', 'me', 'much', 'empty', 'over', 'out', 'fifteen', 'ever', 'enough', 'one', 'because', 'hasnt', 'sixty', 'thereupon', 'whenever', 'give', 'top', 'either', 'how', 'that', 'somewhere', 'without', 'forty', 'still', 'with', 'nothing', 'more', 'twenty', 'besides', 'co', 'together', 'ours', 'hence', 'anyhow', 'most', 'might', 'de', 'etc', 'couldnt', 'or', 'therein', 'we', 'even', 'bill', 'eight', 'beyond', 'become', 'who', 'mostly', 'per', 'whereafter', 'show', 'in', 'must', 'her', 'some', 'former', 'down', 'least', 'take', 'a', 'many', 'almost', 'found', 'yourselves', 'sometime', 'through', 'by', 'latterly', 'i', 'when', 'nine', 'these', 'alone', 'while', 'this', 'those', 'somehow', 'there', 'twelve', 'wherever', 'around']\n"
     ]
    }
   ],
   "source": [
    "print(ENGLISH_STOP_WORDS_LIST)\n",
    "# remove 'not' as it is quite an import contrast word\n",
    "ENGLISH_STOP_WORDS_LIST.remove('not') # only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e71f2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the helper functions to clean the data depending on which tasks\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "# remove contractions\n",
    "def contraction_removal(phrase):\n",
    "    # replace bad characters\n",
    "    phrase = phrase.replace(u'’', u\"'\")\n",
    "    phrase = phrase.replace(u'‘', u\"'\")\n",
    "    # more specific change\n",
    "    phrase = re.sub(r\"won\\'t\", \" will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \" cannot\", phrase)\n",
    "    phrase = re.sub(r\"shan\\'t\", \" shall not\", phrase)\n",
    "    phrase = re.sub(r\"I ain\\t\", \" I am not\", phrase)\n",
    "    phrase = re.sub(r\"i ain\\t\", \" I am not\", phrase)\n",
    "    phrase = re.sub(r\"She ain\\t\", \" she is not\", phrase)\n",
    "    phrase = re.sub(r\"He ain\\t\", \" he is not\", phrase)\n",
    "    phrase = re.sub(r\"he ain\\t\", \" he am not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "# remove url, mention, reserved words, emoji, smiley and number\n",
    "# using tweet preprocessor library here\n",
    "def tweet_preprocessor(text, config):\n",
    "    if config == 'deep_clean' or config == 'ecpe':\n",
    "        p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI, p.OPT.RESERVED, p.OPT.SMILEY)\n",
    "    elif config == 'vader':\n",
    "        p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.SMILEY)\n",
    "    text = p.clean(text)\n",
    "    # remove the url starting with www\n",
    "    text = re.sub(r\"\\bwww.\\w+\", \"\", text)\n",
    "    # just remove hashtag (not the whole hashtag and words)\n",
    "    text = re.sub(r\"#\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# remove extra spaces and stopwords, do lowercase, and remove punctuations.\n",
    "def clean_text(text, removeLower=True, removeNumbers=True, removePunct=True, removeExtraSpace=True):\n",
    "    text = cleantext.clean(text, \n",
    "                    lowercase=removeLower, \n",
    "                    numbers=removeNumbers, \n",
    "                    punct=removePunct,\n",
    "                    extra_spaces=removeExtraSpace)\n",
    "    return str(text)\n",
    "\n",
    "# keep only alphabets (only for deep clean)\n",
    "def keep_alphabet_only(text):\n",
    "    return re.sub('[^a-zA-Z- ]+', '', text)\n",
    "\n",
    "# keep alphabets, some basic punctuations and numbera\n",
    "def keep_selected(text):\n",
    "    emoji_pat = '[\\U0001F300-\\U0001F64F\\U0001F680-\\U0001F6FF\\u2600-\\u26FF\\u2700-\\u27BF]'\n",
    "    shrink_whitespace_reg = re.compile(r'\\s{2,}')\n",
    "    reg = re.compile(r'({})|[^a-zA-Z0-9,.!?-]'.format(emoji_pat)) # line a\n",
    "    result = reg.sub(lambda x: ' {} '.format(x.group(1)) if x.group(1) else ' ', text)\n",
    "    return shrink_whitespace_reg.sub(' ', result)\n",
    "\n",
    "# eliminate letters who appeared more than twice in the text\n",
    "def eliminate_multi_letters(text):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "'''\n",
    "# autocorrect to fix spelling errors\n",
    "spell = Speller()\n",
    "def autocorrect(text):\n",
    "    return spell(text)\n",
    "'''\n",
    "\n",
    "def stopword_removal(text):\n",
    "    words = [word for word in text.split() if word.lower() not in ENGLISH_STOP_WORDS_LIST]\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "\n",
    "# perform lemmatization here\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    text_list = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    listToStr = ' '.join([str(elem) for elem in text_list])\n",
    "    return listToStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce983022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d05b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9e02b1",
   "metadata": {},
   "source": [
    "## Deep Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26db301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lemmatization here\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61665beb",
   "metadata": {},
   "source": [
    "To generate the following files:   \n",
    "emotion_classification_cleaned_long_data_{type}.csv (train and dev)   \n",
    "emotion_classification_cleaned_short_data_{type}.csv (train and dev)  \n",
    "emotion_classification_cleaned_toy_data_{type}.csv (train and dev)  \n",
    "emotion_classification_cleaned_combined_data_{type}.csv (train and dev)      \n",
    "  \n",
    "emotion_intensity_wassa_sadness_combined_{type}.csv (train and dev)   \n",
    "emotion_intensity_wassa_anger_combined_{type}.csv (train and dev)   \n",
    "emotion_intensity_wassa_fear_combined_{type}.csv (train and dev)   \n",
    "   \n",
    "Only depressed data here  \n",
    "emotion_intensity_depressed_clean_long_data_test.csv (test set for machine learning portion)  \n",
    "emotion_intensity_depressed_clean_short_data_test.csv (test set for machine learning portion)  \n",
    "  \n",
    "Total: 16 data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8a6a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the deep clean data\n",
    "def deep_clean(text):\n",
    "    text = contraction_removal(text)\n",
    "    text = tweet_preprocessor(text, 'deep_clean')\n",
    "    text = stopword_removal(text)\n",
    "    text = clean_text(text, \n",
    "                       removeLower=True, \n",
    "                       removeNumbers=True, \n",
    "                       removePunct=True, \n",
    "                       removeExtraSpace=True)\n",
    "    text = keep_alphabet_only(text)\n",
    "    text = eliminate_multi_letters(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804e046",
   "metadata": {},
   "source": [
    "## Vader and text2emotion data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0215fd3",
   "metadata": {},
   "source": [
    "To generate the following files:  \n",
    "emotion_intensity_depressed_clean_long_data_vader_t2e.csv  \n",
    "emotion_intensity_depressed_clean_short_data_vader_t2e.csv\n",
    "\n",
    "Total: 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "248b18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the vader and t2e data\n",
    "def vader_and_t2e_clean(text):\n",
    "    text = contraction_removal(text)\n",
    "    text = tweet_preprocessor(text, 'vader')\n",
    "    text = clean_text(text, \n",
    "                      removeLower=False, \n",
    "                      removeNumbers=True, \n",
    "                      removePunct=False, \n",
    "                      removeExtraSpace=True)\n",
    "    text = keep_selected(text)\n",
    "    text = eliminate_multi_letters(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e5714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5959c36e",
   "metadata": {},
   "source": [
    "## ECPE data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be4310",
   "metadata": {},
   "source": [
    "To generate the following file:  \n",
    "ecpe_cleaned_long_data.csv\n",
    "\n",
    "Total: 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71a044d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecpe_clean(text):\n",
    "    text = contraction_removal(text)\n",
    "    text = tweet_preprocessor(text, 'ecpe')\n",
    "    text = clean_text(text, \n",
    "                      removeLower=False, \n",
    "                      removeNumbers=False, \n",
    "                      removePunct=False, \n",
    "                      removeExtraSpace=True)\n",
    "    text = eliminate_multi_letters(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d71e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24bec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0642126c",
   "metadata": {},
   "source": [
    "## Load all the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8ac8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw data in\n",
    "toy_data = pd.read_csv('./data/toy_data.csv')\n",
    "long_text = pd.read_csv('./data/long_text_combined.csv')\n",
    "long_text_only_depressed = pd.read_csv('./data/long_text_only_depressed.csv')\n",
    "short_text = pd.read_csv('./data/short_text.csv')\n",
    "short_text_only_depressed = pd.read_csv('./data/short_text_only_depressed.csv')\n",
    "wassa_anger_train_raw = pd.read_csv('./data/wassa_anger_train_raw.csv')\n",
    "wassa_anger_dev_raw = pd.read_csv('./data/wassa_anger_dev_raw.csv')\n",
    "wassa_fear_train_raw = pd.read_csv('./data/wassa_fear_train_raw.csv')\n",
    "wassa_fear_dev_raw = pd.read_csv('./data/wassa_fear_dev_raw.csv')\n",
    "wassa_sadness_train_raw = pd.read_csv('./data/wassa_sadness_train_raw.csv')\n",
    "wassa_sadness_dev_raw = pd.read_csv('./data/wassa_sadness_dev_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581ce5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e58938a",
   "metadata": {},
   "source": [
    "## Check the dataset \n",
    "check the standardized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f35c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label\n",
      "0  just had a real good moment. i missssssssss hi...      0\n",
      "1         is reading manga  http://plurk.com/p/mzp1e      0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    8000\n",
       "1    2314\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(toy_data.head(2))\n",
    "toy_data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2feef4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label\n",
      "0  Thoughts on multi-family and multi-generationa...      0\n",
      "1  God \"God moves towards those who need him the ...      1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    1437\n",
       "0    1292\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(long_text.head(2))\n",
    "long_text['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ac9049bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label\n",
      "0  Just another night. Another night of feeling l...      1\n",
      "1  Is it possible to fake depression? I have been...      1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    1437\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(long_text_only_depressed.head(2))\n",
    "long_text_only_depressed['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55ac4a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label\n",
      "0  Today in Selfcare: beauty &amp; laughs Kung Fu...      0\n",
      "1  I get to spend New Year's home again alone and...      1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2357\n",
       "1     843\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(short_text.head(2))\n",
    "short_text['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26528ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label\n",
      "0  I get to spend New Year's home again alone and...      1\n",
      "1  Depressed and lonely /: Stuck in a deep, never...      1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    843\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(short_text_only_depressed.head(2))\n",
    "short_text_only_depressed['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9df4e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  Score\n",
       "0  How the fu*k! Who the heck! moved my fridge!.....  anger  0.938\n",
       "1  So my Indian Uber driver just called someone t...  anger  0.896"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wassa_anger_train_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "768be8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  Score\n",
       "0  @ZubairSabirPTI  pls dont insult the word 'Molna'  anger  0.479\n",
       "1  @ArcticFantasy I would have almost took offens...  anger  0.458"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wassa_anger_dev_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dfd3d841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I feel like I am drowning. #depression #anxiet...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I get so nervous even thinking about talking t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Label  Score\n",
       "0  I feel like I am drowning. #depression #anxiet...  fear  0.979\n",
       "1  I get so nervous even thinking about talking t...  fear  0.979"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wassa_fear_train_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d90ad2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I know this is going to be one of those nights...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is #horrible: Lewis Dunk has begun networ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Label  Score\n",
       "0  I know this is going to be one of those nights...  fear  0.771\n",
       "1  This is #horrible: Lewis Dunk has begun networ...  fear  0.479"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wassa_fear_dev_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "083223bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Depression sucks! #depression</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feeling worthless as always #depression</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text    Label  Score\n",
       "0            Depression sucks! #depression  sadness  0.958\n",
       "1  Feeling worthless as always #depression  sadness  0.958"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wassa_sadness_train_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa9c6c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@1johndes ball watching &amp;amp; Rojo'd header wa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A pessimist is someone who, when opportunity k...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Label  Score\n",
       "0  @1johndes ball watching &amp; Rojo'd header wa...  sadness  0.583\n",
       "1  A pessimist is someone who, when opportunity k...  sadness  0.188"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wassa_sadness_dev_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8f8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f7edb01",
   "metadata": {},
   "source": [
    "## Settle the data imbalance issue first\n",
    "Resolve it with downsampling of the larger class dataset   \n",
    "Affected dataset:  \n",
    "- toy_data  \n",
    "- long_text  \n",
    "- short_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04bae459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2314\n",
       "0    2314\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy data\n",
    "toy_data_0 = toy_data[toy_data['Label'] == 0]\n",
    "toy_data_1 = toy_data[toy_data['Label'] == 1]\n",
    "\n",
    "# downsample the data of non-depression class to fit the number of the depression class\n",
    "toy_data_0_down = toy_data[toy_data['Label'] == 0].sample(len(toy_data_1), replace=False)\n",
    "#print(toy_data_0_down.shape)\n",
    "\n",
    "# concatenate back the data into 1 dataset\n",
    "frames = [toy_data_0_down, toy_data_1]\n",
    "toy_data_balanced = pd.concat(frames)\n",
    "\n",
    "# shuffle dataset for better data distribution\n",
    "toy_data_balanced = toy_data_balanced.sample(frac=1).reset_index(drop=True)\n",
    "#toy_data_balanced.head(3)\n",
    "toy_data_balanced['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8f3e7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1292\n",
       "0    1292\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# long text data\n",
    "long_text_0 = long_text[long_text['Label'] == 0]\n",
    "long_text_1 = long_text[long_text['Label'] == 1]\n",
    "\n",
    "# downsample the data of non-depression class to fit the number of the depression class\n",
    "long_text_1_down = long_text[long_text['Label'] == 1].sample(len(long_text_0), replace=False)\n",
    "\n",
    "# concatenate back the data into 1 dataset\n",
    "frames = [long_text_0, long_text_1_down]\n",
    "long_text_balanced = pd.concat(frames)\n",
    "\n",
    "# shuffle dataset for better data distribution\n",
    "long_text_balanced = long_text_balanced.sample(frac=1).reset_index(drop=True)\n",
    "long_text_balanced['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e509fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    843\n",
       "0    843\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# long text data\n",
    "short_text_0 = short_text[short_text['Label'] == 0]\n",
    "short_text_1 = short_text[short_text['Label'] == 1]\n",
    "\n",
    "# downsample the data of non-depression class to fit the number of the depression class\n",
    "short_text_0_down = short_text[short_text['Label'] == 0].sample(len(short_text_1), replace=False)\n",
    "\n",
    "# concatenate back the data into 1 dataset\n",
    "frames = [short_text_0_down, short_text_1]\n",
    "short_text_balanced = pd.concat(frames)\n",
    "\n",
    "# shuffle dataset for better data distribution\n",
    "short_text_balanced = short_text_balanced.sample(frac=1).reset_index(drop=True)\n",
    "short_text_balanced['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f512b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c16e133f",
   "metadata": {},
   "source": [
    "## Proceed with the cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472514",
   "metadata": {},
   "source": [
    "**Emotion Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "054b569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4628/4628 [00:02<00:00, 1921.11it/s]\n"
     ]
    }
   ],
   "source": [
    "text_cleaned_list = []\n",
    "for i in tqdm(toy_data_balanced['Text']):\n",
    "    temp = deep_clean(i)\n",
    "    text_cleaned_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b55436e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@HarlemLanes Right!  I am trying to convince m...</td>\n",
       "      <td>0</td>\n",
       "      <td>right trying convince homegirl thats lounge ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new vid!  http://tiny.cc/staybeautiful</td>\n",
       "      <td>0</td>\n",
       "      <td>new vid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@uNdlunkulu_Xoli Firstly if she is ready and w...</td>\n",
       "      <td>1</td>\n",
       "      <td>firstly ready welling baby let soshe just came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lol that feel when the depression hits u in d ...</td>\n",
       "      <td>1</td>\n",
       "      <td>lol feel depression hit u d face right ur study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I cant wait to see you again dude</td>\n",
       "      <td>0</td>\n",
       "      <td>wait dude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>Need Some Help Healing Grief and Heartache? Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>need help healing grief heartache podcast sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>Exercise can prevent depression, no matter you...</td>\n",
       "      <td>1</td>\n",
       "      <td>exercise prevent depression matter age gender ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>@ShizuStreams shizu is the best healer.  She h...</td>\n",
       "      <td>1</td>\n",
       "      <td>shizu best healer heals sadness depression voi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>@Desireeeeee really me to.!</td>\n",
       "      <td>0</td>\n",
       "      <td>really to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627</th>\n",
       "      <td>@FaereWolf I won't go that far, but the depres...</td>\n",
       "      <td>1</td>\n",
       "      <td>not far depression lost today</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4628 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label  \\\n",
       "0     @HarlemLanes Right!  I am trying to convince m...      0   \n",
       "1                new vid!  http://tiny.cc/staybeautiful      0   \n",
       "2     @uNdlunkulu_Xoli Firstly if she is ready and w...      1   \n",
       "3     lol that feel when the depression hits u in d ...      1   \n",
       "4                    I cant wait to see you again dude       0   \n",
       "...                                                 ...    ...   \n",
       "4623  Need Some Help Healing Grief and Heartache? Th...      1   \n",
       "4624  Exercise can prevent depression, no matter you...      1   \n",
       "4625  @ShizuStreams shizu is the best healer.  She h...      1   \n",
       "4626                       @Desireeeeee really me to.!       0   \n",
       "4627  @FaereWolf I won't go that far, but the depres...      1   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     right trying convince homegirl thats lounge ty...  \n",
       "1                                               new vid  \n",
       "2     firstly ready welling baby let soshe just came...  \n",
       "3       lol feel depression hit u d face right ur study  \n",
       "4                                             wait dude  \n",
       "...                                                 ...  \n",
       "4623  need help healing grief heartache podcast sure...  \n",
       "4624  exercise prevent depression matter age gender ...  \n",
       "4625  shizu best healer heals sadness depression voi...  \n",
       "4626                                          really to  \n",
       "4627                      not far depression lost today  \n",
       "\n",
       "[4628 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data_balanced['text_cleaned'] = text_cleaned_list\n",
    "toy_data_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "23bde72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@HarlemLanes Right!  I am trying to convince m...</td>\n",
       "      <td>0</td>\n",
       "      <td>right trying convince homegirl thats lounge ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new vid!  http://tiny.cc/staybeautiful</td>\n",
       "      <td>0</td>\n",
       "      <td>new vid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@uNdlunkulu_Xoli Firstly if she is ready and w...</td>\n",
       "      <td>1</td>\n",
       "      <td>firstly ready welling baby let soshe just came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lol that feel when the depression hits u in d ...</td>\n",
       "      <td>1</td>\n",
       "      <td>lol feel depression hit u d face right ur study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I cant wait to see you again dude</td>\n",
       "      <td>0</td>\n",
       "      <td>wait dude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>Need Some Help Healing Grief and Heartache? Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>need help healing grief heartache podcast sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>Exercise can prevent depression, no matter you...</td>\n",
       "      <td>1</td>\n",
       "      <td>exercise prevent depression matter age gender ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>@ShizuStreams shizu is the best healer.  She h...</td>\n",
       "      <td>1</td>\n",
       "      <td>shizu best healer heals sadness depression voi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>@Desireeeeee really me to.!</td>\n",
       "      <td>0</td>\n",
       "      <td>really to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627</th>\n",
       "      <td>@FaereWolf I won't go that far, but the depres...</td>\n",
       "      <td>1</td>\n",
       "      <td>not far depression lost today</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4628 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label  \\\n",
       "0     @HarlemLanes Right!  I am trying to convince m...      0   \n",
       "1                new vid!  http://tiny.cc/staybeautiful      0   \n",
       "2     @uNdlunkulu_Xoli Firstly if she is ready and w...      1   \n",
       "3     lol that feel when the depression hits u in d ...      1   \n",
       "4                    I cant wait to see you again dude       0   \n",
       "...                                                 ...    ...   \n",
       "4623  Need Some Help Healing Grief and Heartache? Th...      1   \n",
       "4624  Exercise can prevent depression, no matter you...      1   \n",
       "4625  @ShizuStreams shizu is the best healer.  She h...      1   \n",
       "4626                       @Desireeeeee really me to.!       0   \n",
       "4627  @FaereWolf I won't go that far, but the depres...      1   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     right trying convince homegirl thats lounge ty...  \n",
       "1                                               new vid  \n",
       "2     firstly ready welling baby let soshe just came...  \n",
       "3       lol feel depression hit u d face right ur study  \n",
       "4                                             wait dude  \n",
       "...                                                 ...  \n",
       "4623  need help healing grief heartache podcast sure...  \n",
       "4624  exercise prevent depression matter age gender ...  \n",
       "4625  shizu best healer heals sadness depression voi...  \n",
       "4626                                          really to  \n",
       "4627                      not far depression lost today  \n",
       "\n",
       "[4628 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save a backup cleaned data before further preprocessing\n",
    "toy_data_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "86304c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data_balanced.to_csv('./data/backup_cleaned_data/toy_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to remove empty or less than 1 word entry\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
