do people ever find their jobs interesting?
you've gone to school and studied and worked hard to get the job you've alway wanted.. is it as interesting as you hoped it'd be before you got the job? or was it just a waste of time?

cause all i see online are people complaining that your dream job isn't really what it seems and i wanted to know if life is just gonna keep getting more depressing even if you get your dream job